# The main entry point of your workflow.
# After configuring, running snakemake -n in a clone of this repository should successfully execute a dry-run of the workflow.

import os
import pathlib
import pandas as pd
from snakemake.remote.S3 import RemoteProvider as S3RemoteProvider
from snakemake.remote.HTTP import RemoteProvider as HTTPRemoteProvider
from snakemake.utils import validate

S3 = S3RemoteProvider()

sys.path.insert(0, ".")
from lib import target_construction as tc

shell.executable("/bin/bash")
shell.prefix("set -euo pipefail; ")


configfile: "config/config.yaml"


validate(config, "../schema/global_config_schema.yaml")

tempDir = "temp"
manifest_experiment = config["experiment-manifest"]
manifest_reference = config["reference-manifest"]
manifest_comparisons = config["comparisons-manifest"]
manifest_experiment = pd.read_csv(manifest_experiment, sep="\t").set_index(
    "experimental_dataset", drop=False
)
manifest_reference = pd.read_csv(manifest_reference, sep="\t").set_index(
    "reference_dataset", drop=False
)
manifest_comparisons = pd.read_csv(manifest_comparisons, sep="\t")
reference_build = config["genome-build"]


validate(manifest_experiment, "../schema/experiment_manifest_schema.yaml")
validate(manifest_reference, "../schema/reference_manifest_schema.yaml")
validate(manifest_comparisons, "../schema/comparisons_manifest_schema.yaml")


TARGETS = (tc.construct_targets(config, manifest_experiment, manifest_comparisons),)


ruleorder: sv_svdb_within_dataset > download_experimental_data
ruleorder: sv_svdb_within_dataset > download_reference_data


rule all:
    input:
        TARGETS,


include: "rules/acquire_data.smk"
include: "rules/happy.smk"
include: "rules/reference_data.smk"
include: "rules/reports.smk"
include: "rules/svdb.smk"
include: "rules/vcfeval.smk"
